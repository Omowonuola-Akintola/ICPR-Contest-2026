{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":126118,"databundleVersionId":14933142,"sourceType":"competition"},{"sourceId":14744436,"sourceType":"datasetVersion","datasetId":9423234}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install torchgeo --quiet\n# # !pip install wandb --quiet\n# !pip install lightning --quiet\n# !pip install prettytable","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:23.994872Z","iopub.execute_input":"2026-02-05T18:20:23.995374Z","iopub.status.idle":"2026-02-05T18:20:23.999086Z","shell.execute_reply.started":"2026-02-05T18:20:23.995343Z","shell.execute_reply":"2026-02-05T18:20:23.998500Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# os.cpu_count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:24.000504Z","iopub.execute_input":"2026-02-05T18:20:24.000821Z","iopub.status.idle":"2026-02-05T18:20:24.009958Z","shell.execute_reply.started":"2026-02-05T18:20:24.000800Z","shell.execute_reply":"2026-02-05T18:20:24.009394Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset\nimport rasterio\nimport numpy as np\nfrom rasterio.enums import Resampling\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as T\nfrom lightning.pytorch import Trainer\nfrom torchvision import transforms  \nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models import ResNet50_Weights\nimport kornia.augmentation as K\nimport torch.nn.functional as F\nimport torchgeo.transforms as T\nfrom lightning.pytorch.loggers import CSVLogger\nimport glob\nimport os\nimport shutil\nimport random\nfrom prettytable import PrettyTable\nrandom.seed(42) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:24.010654Z","iopub.execute_input":"2026-02-05T18:20:24.010871Z","iopub.status.idle":"2026-02-05T18:20:33.003473Z","shell.execute_reply.started":"2026-02-05T18:20:24.010844Z","shell.execute_reply":"2026-02-05T18:20:33.002887Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Info from metadata.json\n# B1\t1830 Ã— 1830\t60â€¯m\n# B2\t10980 Ã— 10980\t10â€¯m\n# B3\t10980 Ã— 10980\t10â€¯m\n# B4\t10980 Ã— 10980\t10â€¯m\n# B5\t5490 Ã— 5490\t20â€¯m\n# B6\t5490 Ã— 5490\t20â€¯m\n# B7\t5490 Ã— 5490\t20â€¯m\n# B8\t10980 Ã— 10980\t10â€¯m\n# B8A\t5490 Ã— 5490\t20â€¯m\n# B9\t1830 Ã— 1830\t60â€¯m\n# B11\t5490 Ã— 5490\t20â€¯m\n# B12\t5490 Ã— 5490\t20â€¯m","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:33.004279Z","iopub.execute_input":"2026-02-05T18:20:33.004631Z","iopub.status.idle":"2026-02-05T18:20:33.008194Z","shell.execute_reply.started":"2026-02-05T18:20:33.004588Z","shell.execute_reply":"2026-02-05T18:20:33.007529Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Sub-sample 3k Data","metadata":{}},{"cell_type":"code","source":"# root_dir = \"/Volumes/WD_Rabina/competition/extracted_data/s2a\"\n# # List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# # print(scenes)\n# print(len(scenes))\n\n# no_of_files=3000\n\n# # Randomly select 3000 scenes (without replacement)\n# selected_scenes = random.sample(scenes, k=3000)\n\n# print(f\"Total selected scenes: {len(selected_scenes)}\")\n# # print(selected_scenes[:10])  # show first 10 for sanity check\n\n# # Path to new folder where selected scenes will be copied\n# destination_root = \"data/s2a_3k_sample\"\n# os.makedirs(destination_root, exist_ok=True)  # create folder if it doesn't exist\n\n# # Copy each selected folder\n# count=0\n# for scene_path in selected_scenes:\n#     # Get folder name only (e.g., \"000015\")\n#     folder_name = os.path.basename(os.path.normpath(scene_path))\n    \n#     # Destination path\n#     dest_path = os.path.join(destination_root, folder_name)\n#     count=count+1\n#     print(count)\n#     # Copy folder and all its contents\n#     shutil.copytree(scene_path, dest_path)\n\n# print(f\"Copied {len(selected_scenes)} folders to {destination_root}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:33.010055Z","iopub.execute_input":"2026-02-05T18:20:33.010438Z","iopub.status.idle":"2026-02-05T18:20:33.023398Z","shell.execute_reply.started":"2026-02-05T18:20:33.010413Z","shell.execute_reply":"2026-02-05T18:20:33.022821Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Settings","metadata":{}},{"cell_type":"code","source":"target_size = 224\ntarget_batch_size=128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=20\nuse_peft = True  \nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nlogger = CSVLogger(\"logs\", name=f\"metrics_{timestamp}\")\n\n# logger = CSVLogger(\"logs\", name=f\"try_{timestamp}\")\n\n# Default\n# # Similar to SimCLR: https://arxiv.org/abs/2002.05709\n# aug1 = aug2 = K.AugmentationSequential(\n#     K.RandomResizedCrop(size=(size, size), scale=(0.2, 1)),\n#     K.RandomBrightness(brightness=(0.6, 1.4), p=0.8),\n#     K.RandomContrast(contrast=(0.6, 1.4), p=0.8),\n#     T.RandomGrayscale(weights=weights, p=0.2),\n#     K.RandomGaussianBlur(kernel_size=(ks, ks), sigma=(0.1, 2), p=0.5),\n#     K.RandomHorizontalFlip(),\n#     K.RandomVerticalFlip(),  # added\n#     data_keys=['input'],\n# )\n\naug = K.AugmentationSequential(\n    K.RandomResizedCrop(size=(target_size, target_size), scale=(0.4, 1.0)),\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n    K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n    data_keys=['input'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:33.024223Z","iopub.execute_input":"2026-02-05T18:20:33.024428Z","iopub.status.idle":"2026-02-05T18:20:33.043887Z","shell.execute_reply.started":"2026-02-05T18:20:33.024406Z","shell.execute_reply":"2026-02-05T18:20:33.043088Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}\n\ndef calculate_stats(dataset, n_samples=500):\n    mean = 0\n    std = 0\n    print(len(dataset))\n    n = min(len(dataset), n_samples)\n\n    for i in range(n):\n        sample = dataset[i]\n        img = sample[\"image\"]   # <-- key fix\n\n        mean += img.mean(dim=(1, 2))\n        std += img.std(dim=(1, 2))\n\n    mean /= n\n    std /= n\n\n    return mean, std\n\n\n\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:33.044928Z","iopub.execute_input":"2026-02-05T18:20:33.045663Z","iopub.status.idle":"2026-02-05T18:20:33.060506Z","shell.execute_reply.started":"2026-02-05T18:20:33.045635Z","shell.execute_reply":"2026-02-05T18:20:33.059838Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# root_dir = \"data/s2a\"\nroot_dir = \"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample\"\n# List all folders\nscenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# scenes = [\"data/s2a/000015\", \"data/s2a/000016\"]  # list of scene folders\nbands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n# print(scenes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:33.061408Z","iopub.execute_input":"2026-02-05T18:20:33.061749Z","iopub.status.idle":"2026-02-05T18:20:34.091435Z","shell.execute_reply.started":"2026-02-05T18:20:33.061717Z","shell.execute_reply":"2026-02-05T18:20:34.090861Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# One time run to get mean and std\n# temp_dataset = SSLDataset(scenes, bands)\n# mean, std = calculate_stats(temp_dataset)\n# print(mean)\n# print(std)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:34.092212Z","iopub.execute_input":"2026-02-05T18:20:34.092508Z","iopub.status.idle":"2026-02-05T18:20:34.097382Z","shell.execute_reply.started":"2026-02-05T18:20:34.092482Z","shell.execute_reply":"2026-02-05T18:20:34.096687Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"mean= [1041.5322, 1224.2570, 1549.6492, 1815.5840, 2171.1243, 2729.5166,\n        2990.2266, 3074.2515, 3162.9661, 3260.7983,    0.0000, 2969.8357,\n        2335.3250]\nstd = [328.5996, 410.0965, 443.5781, 547.2238, 519.4624, 547.1485, 606.4136,\n        649.6067, 621.7164, 687.0721,   0.0000, 574.0366, 560.9932]\n\n# mean = [2358.7412, 2402.7629, 2580.9255, 2614.2227, 3057.6877, 3578.1008,\n#         3796.8345, 3795.6868, 3947.5913, 4833.6362,    0.0000, 3379.1743,\n#         2666.4465]\n# std = [2994.4861, 2847.0354, 2542.9307, 2411.1196, 2399.0249, 2137.6804,\n#         2036.8357, 2042.7140, 1957.9615, 3559.4121,    0.0000, 1535.7960,\n#         1393.8278]\n\n# to avoid 0 std\nstd = [max(s, 1e-5) for s in std]   \n\n# define transform\ntransform = transforms.Compose([\n    transforms.Resize((target_size, target_size)),\n    transforms.Normalize(mean=mean, std=std)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:34.098949Z","iopub.execute_input":"2026-02-05T18:20:34.099239Z","iopub.status.idle":"2026-02-05T18:20:34.108003Z","shell.execute_reply.started":"2026-02-05T18:20:34.099215Z","shell.execute_reply":"2026-02-05T18:20:34.107251Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = SSLDataset(scenes, bands, transforms=transform)\nprint(len(dataset))\nprint(dataset[0]['image'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:34.108853Z","iopub.execute_input":"2026-02-05T18:20:34.109165Z","iopub.status.idle":"2026-02-05T18:20:44.760281Z","shell.execute_reply.started":"2026-02-05T18:20:34.109141Z","shell.execute_reply":"2026-02-05T18:20:44.759502Z"}},"outputs":[{"name":"stdout","text":"15426\ntorch.Size([13, 224, 224])\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=target_batch_size, shuffle=True, num_workers=target_num_workers)\nnum_batches = len(data_loader)\nprint(\"Number of batches:\", num_batches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:44.761255Z","iopub.execute_input":"2026-02-05T18:20:44.761570Z","iopub.status.idle":"2026-02-05T18:20:44.766570Z","shell.execute_reply.started":"2026-02-05T18:20:44.761523Z","shell.execute_reply":"2026-02-05T18:20:44.765873Z"}},"outputs":[{"name":"stdout","text":"Number of batches: 121\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:20:44.767413Z","iopub.execute_input":"2026-02-05T18:20:44.767714Z","iopub.status.idle":"2026-02-05T18:20:44.821737Z","shell.execute_reply.started":"2026-02-05T18:20:44.767688Z","shell.execute_reply":"2026-02-05T18:20:44.821182Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"task = MoCoTask(\n    model=\"resnet50\",      \n    weights=ResNet50_Weights.SENTINEL2_ALL_MOCO,\n    in_channels=13,       \n    version=2,             # MoCo v2\n    size=target_size,          \n    augmentation1=aug,\n    augmentation2=aug,\n    lr=1e-4,\n    # patience=5\n)\n\n# -----------------------------\n# PEFT / Full Fine-Tuning Logic\n# -----------------------------\nif use_peft:\n    print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n    for name, param in task.backbone.named_parameters():\n        if \"layer4\" in name:      # optionally fine-tune last residual block\n            # print(\"Layer 4 trainable\")\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\nelse:\n    print(\"Full fine-tuning: backbone and projection head trainable...\")\n    for param in task.backbone.parameters():\n        param.requires_grad = True\n\n# Momentum backbone always frozen\nfor param in task.backbone_momentum.parameters():\n    param.requires_grad = False\n\n# Projection head always trainable\nfor param in task.projection_head.parameters():\n    param.requires_grad = True\n\n# Example usage for your task\nsummary_trainable(task)\n\ntrainer = Trainer(\n    max_epochs=target_max_epoch,\n    enable_progress_bar=True, \n    log_every_n_steps=num_batches,\n    precision=32,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    logger=logger)\ntrainer.fit(task, data_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:22:32.841205Z","iopub.execute_input":"2026-02-05T18:22:32.842192Z","iopub.status.idle":"2026-02-05T19:47:03.075395Z","shell.execute_reply.started":"2026-02-05T18:22:32.842156Z","shell.execute_reply":"2026-02-05T19:47:03.074798Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchgeo/trainers/moco.py:209: UserWarning: MoCo v2 only uses 2 layers in its projection head\n  warnings.warn('MoCo v2 only uses 2 layers in its projection head')\n/usr/local/lib/python3.12/dist-packages/torchgeo/trainers/moco.py:211: UserWarning: MoCo v2 uses a memory bank\n  warnings.warn('MoCo v2 uses a memory bank')\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n","output_type":"stream"},{"name":"stdout","text":"Using PEFT: freezing backbone except last block, training projection head...\n+--------------------------+------------------------+------------------+--------------+\n|          Module          |          Type          | Trainable Params | Total Params |\n+--------------------------+------------------------+------------------+--------------+\n|         backbone         |         ResNet         |    14,964,736    |  23,539,392  |\n|    backbone_momentum     |         ResNet         |        0         |  23,539,392  |\n|     projection_head      |   MoCoProjectionHead   |    26,222,848    |  26,222,848  |\n| projection_head_momentum |   MoCoProjectionHead   |        0         |  26,222,848  |\n|        criterion         |       NTXentLoss       |        0         |      0       |\n|      augmentation1       | AugmentationSequential |        0         |      0       |\n+--------------------------+------------------------+------------------+--------------+\nTotal trainable parameters: 41,187,584 (41.19 M)\nTotal parameters: 99,524,480 (99.52 M)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                    \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone                 â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone_momentum        â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                     </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ backbone                 â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ backbone_momentum        â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 41.2 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 58.3 M                                                                                       \n\u001b[1mTotal params\u001b[0m: 99.5 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 398                                                                        \n\u001b[1mModules in train mode\u001b[0m: 460                                                                                         \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 41.2 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 58.3 M                                                                                       \n<span style=\"font-weight: bold\">Total params</span>: 99.5 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 398                                                                        \n<span style=\"font-weight: bold\">Modules in train mode</span>: 460                                                                                         \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6bb608816340e1846bca8157bda160"}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=20` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(task.trainer.logged_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:47:03.079687Z","iopub.execute_input":"2026-02-05T19:47:03.079953Z","iopub.status.idle":"2026-02-05T19:47:03.087785Z","shell.execute_reply.started":"2026-02-05T19:47:03.079908Z","shell.execute_reply":"2026-02-05T19:47:03.087050Z"}},"outputs":[{"name":"stdout","text":"{'train_ssl_std': tensor(0.0162), 'train_loss': tensor(4.1676)}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Save the backbone encoder only\ntorch.save(task.backbone.state_dict(),f\"ssl_backbone_{timestamp}.pth\")\n\ntorch.save(task.projection_head.state_dict(), f\"projection_head_{timestamp}.pth\")\ntrainer.save_checkpoint(f\"ssl_3k_ckpt_{timestamp}.ckpt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:47:03.089125Z","iopub.execute_input":"2026-02-05T19:47:03.089340Z","iopub.status.idle":"2026-02-05T19:47:07.106639Z","shell.execute_reply.started":"2026-02-05T19:47:03.089317Z","shell.execute_reply":"2026-02-05T19:47:07.106042Z"}},"outputs":[{"name":"stderr","text":"`weights_only` was not set, defaulting to `False`.\n","output_type":"stream"}],"execution_count":18}]}