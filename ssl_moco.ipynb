{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":126118,"databundleVersionId":14933142,"sourceType":"competition"},{"sourceId":14744436,"sourceType":"datasetVersion","datasetId":9423234}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# os.cpu_count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset\nimport rasterio\nimport numpy as np\nfrom rasterio.enums import Resampling\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as T\nfrom lightning.pytorch import Trainer\nfrom torchvision import transforms  \nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models import ResNet50_Weights\nimport kornia.augmentation as K\nimport torch.nn.functional as F\nimport torchgeo.transforms as T\nfrom lightning.pytorch.loggers import CSVLogger\nimport glob\nimport os\nimport shutil\nimport random\nfrom prettytable import PrettyTable\nrandom.seed(42) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Info from metadata.json\n# B1\t1830 × 1830\t60 m\n# B2\t10980 × 10980\t10 m\n# B3\t10980 × 10980\t10 m\n# B4\t10980 × 10980\t10 m\n# B5\t5490 × 5490\t20 m\n# B6\t5490 × 5490\t20 m\n# B7\t5490 × 5490\t20 m\n# B8\t10980 × 10980\t10 m\n# B8A\t5490 × 5490\t20 m\n# B9\t1830 × 1830\t60 m\n# B11\t5490 × 5490\t20 m\n# B12\t5490 × 5490\t20 m","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sub-sample 3k Data","metadata":{}},{"cell_type":"code","source":"# root_dir = \"/Volumes/WD_Rabina/competition/extracted_data/s2a\"\n# # List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# # print(scenes)\n# print(len(scenes))\n\n# no_of_files=3000\n\n# # Randomly select 3000 scenes (without replacement)\n# selected_scenes = random.sample(scenes, k=3000)\n\n# print(f\"Total selected scenes: {len(selected_scenes)}\")\n# # print(selected_scenes[:10])  # show first 10 for sanity check\n\n# # Path to new folder where selected scenes will be copied\n# destination_root = \"data/s2a_3k_sample\"\n# os.makedirs(destination_root, exist_ok=True)  # create folder if it doesn't exist\n\n# # Copy each selected folder\n# count=0\n# for scene_path in selected_scenes:\n#     # Get folder name only (e.g., \"000015\")\n#     folder_name = os.path.basename(os.path.normpath(scene_path))\n    \n#     # Destination path\n#     dest_path = os.path.join(destination_root, folder_name)\n#     count=count+1\n#     print(count)\n#     # Copy folder and all its contents\n#     shutil.copytree(scene_path, dest_path)\n\n# print(f\"Copied {len(selected_scenes)} folders to {destination_root}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Settings","metadata":{}},{"cell_type":"code","source":"target_size = 224\ntarget_batch_size=128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=30\nuse_peft = True  \nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nlogger = CSVLogger(\"logs\", name=f\"metrics_{timestamp}\")\n\n# logger = CSVLogger(\"logs\", name=f\"try_{timestamp}\")\n\n# Default\n# # Similar to SimCLR: https://arxiv.org/abs/2002.05709\n# aug1 = aug2 = K.AugmentationSequential(\n#     K.RandomResizedCrop(size=(size, size), scale=(0.2, 1)),\n#     K.RandomBrightness(brightness=(0.6, 1.4), p=0.8),\n#     K.RandomContrast(contrast=(0.6, 1.4), p=0.8),\n#     T.RandomGrayscale(weights=weights, p=0.2),\n#     K.RandomGaussianBlur(kernel_size=(ks, ks), sigma=(0.1, 2), p=0.5),\n#     K.RandomHorizontalFlip(),\n#     K.RandomVerticalFlip(),  # added\n#     data_keys=['input'],\n# )\n\naug = K.AugmentationSequential(\n    K.RandomResizedCrop(size=(target_size, target_size), scale=(0.4, 1.0)),\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n    K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n    data_keys=['input'],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}\n\ndef calculate_stats(dataset, n_samples=500):\n    mean = 0\n    std = 0\n    print(len(dataset))\n    n = min(len(dataset), n_samples)\n\n    for i in range(n):\n        sample = dataset[i]\n        img = sample[\"image\"]   # <-- key fix\n\n        mean += img.mean(dim=(1, 2))\n        std += img.std(dim=(1, 2))\n\n    mean /= n\n    std /= n\n\n    return mean, std\n\n\n\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# root_dir = \"data/s2a\"\nroot_dir = \"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample\"\n# List all folders\nscenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# scenes = [\"data/s2a/000015\", \"data/s2a/000016\"]  # list of scene folders\nbands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n# print(scenes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One time run to get mean and std\n# temp_dataset = SSLDataset(scenes, bands)\n# mean, std = calculate_stats(temp_dataset)\n# print(mean)\n# print(std)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean= [1041.5322, 1224.2570, 1549.6492, 1815.5840, 2171.1243, 2729.5166,\n        2990.2266, 3074.2515, 3162.9661, 3260.7983,    0.0000, 2969.8357,\n        2335.3250]\nstd = [328.5996, 410.0965, 443.5781, 547.2238, 519.4624, 547.1485, 606.4136,\n        649.6067, 621.7164, 687.0721,   0.0000, 574.0366, 560.9932]\n\n# mean = [2358.7412, 2402.7629, 2580.9255, 2614.2227, 3057.6877, 3578.1008,\n#         3796.8345, 3795.6868, 3947.5913, 4833.6362,    0.0000, 3379.1743,\n#         2666.4465]\n# std = [2994.4861, 2847.0354, 2542.9307, 2411.1196, 2399.0249, 2137.6804,\n#         2036.8357, 2042.7140, 1957.9615, 3559.4121,    0.0000, 1535.7960,\n#         1393.8278]\n\n# to avoid 0 std\nstd = [max(s, 1e-5) for s in std]   \n\n# define transform\ntransform = transforms.Compose([\n    transforms.Resize((target_size, target_size)),\n    transforms.Normalize(mean=mean, std=std)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = SSLDataset(scenes, bands, transforms=transform)\nprint(len(dataset))\nprint(dataset[0]['image'].shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=target_batch_size, shuffle=True, num_workers=target_num_workers)\nnum_batches = len(data_loader)\nprint(\"Number of batches:\", num_batches)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\ntask = MoCoTask(\n    model=\"resnet50\",      \n    weights=ResNet50_Weights.SENTINEL2_ALL_MOCO,\n    in_channels=13,       \n    version=2,             # MoCo v2\n    size=target_size,          \n    augmentation1=aug,\n    augmentation2=aug,\n    lr=1e-4,\n    memory_bank_size=2048,\n    temperature=0.15,\n    # gather_distributed=True\n    # patience=5\n)\n\n# -----------------------------\n# PEFT / Full Fine-Tuning Logic\n# -----------------------------\nif use_peft:\n    print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n    for name, param in task.backbone.named_parameters():\n        if \"layer4\" in name:      # optionally fine-tune last residual block\n            # print(\"Layer 4 trainable\")\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\nelse:\n    print(\"Full fine-tuning: backbone and projection head trainable...\")\n    for param in task.backbone.parameters():\n        param.requires_grad = True\n\n# Momentum backbone always frozen\nfor param in task.backbone_momentum.parameters():\n    param.requires_grad = False\n\n# Projection head always trainable\nfor param in task.projection_head.parameters():\n    param.requires_grad = True\n\n# Example usage for your task\nsummary_trainable(task)\n\ntrainer = Trainer(\n    max_epochs=target_max_epoch,\n    enable_progress_bar=True, \n    log_every_n_steps=num_batches,\n    precision=32,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    logger=logger)\n\nstart_time=time.time()\ntrainer.fit(task, data_loader)\nend_time=time.time()\nprint(f\"Training time: {(end_time-start_time)/60} min\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(task.trainer.logged_metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the backbone encoder only\ntorch.save(task.backbone.state_dict(),f\"ssl_backbone_{timestamp}.pth\")\n\ntorch.save(task.projection_head.state_dict(), f\"projection_head_{timestamp}.pth\")\ntrainer.save_checkpoint(f\"ssl_3k_ckpt_{timestamp}.ckpt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}