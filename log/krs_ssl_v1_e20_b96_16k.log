Using device: cpu                                                                                                                                             CPU cores available: 32
CPU cores using: 24
Data root directory: /home/krschap/rabina/data/s2a
========================
Dataset config: DataConfig(data_root_dir='/home/krschap/rabina/data/s2a', compute_stats=False, n_samples=None, batch_size=64, patch_size=264, num_workers=24)
========================
Training config: TrainingConfig(experiment_out_dir='output/ssl_v1_e20_b96_mem_16k', model='resnet50', in_channels=13, version=2, lr=0.0001, use_peft=False, temperature=0.15, memory_bank_size=16000, target_size=224, max_epochs=20, batch_size=96)
Using pre-computed mean and std
166775
torch.Size([13, 224, 224])
Number of batches: 1738
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/torchgeo/trainers/moco.py:209: UserWarning: MoCo v2 only uses 2 layers in its projection head
  warnings.warn('MoCo v2 only uses 2 layers in its projection head')
Full fine-tuning: backbone and projection head trainable...
+--------------------------+------------------------+------------------+--------------+
|          Module          |          Type          | Trainable Params | Total Params |
+--------------------------+------------------------+------------------+--------------+
|         backbone         |         ResNet         |    23,539,392    |  23,539,392  |
|    backbone_momentum     |         ResNet         |        0         |  23,539,392  |
|     projection_head      |   MoCoProjectionHead   |    26,222,848    |  26,222,848  |
| projection_head_momentum |   MoCoProjectionHead   |        0         |  26,222,848  |
|        criterion         |       NTXentLoss       |        0         |      0       |
|      augmentation1       | AugmentationSequential |        0         |      0       |
+--------------------------+------------------------+------------------+--------------+
Total trainable parameters: 49,762,240 (49.76 M)
Total parameters: 99,524,480 (99.52 M)
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
� Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
You are using a CUDA device ('NVIDIA GeForce RTX 4090 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.
����������������������������������������������������������������������������������
�   � Name                     � Type                   � Params � Mode  � FLOPs �
����������������������������������������������������������������������������������
� 0 � backbone                 � ResNet                 � 23.5 M � train �     0 �
� 1 � backbone_momentum        � ResNet                 � 23.5 M � train �     0 �
� 2 � projection_head          � MoCoProjectionHead     � 26.2 M � train �     0 �
� 3 � projection_head_momentum � MoCoProjectionHead     � 26.2 M � train �     0 �
� 4 � criterion                � NTXentLoss             �      0 � train �     0 �
� 5 � augmentation1            � AugmentationSequential �      0 � train �     0 �
����������������������������������������������������������������������������������
Trainable params: 49.8 M
Non-trainable params: 49.8 M
Total params: 99.5 M
Total estimated model params size (MB): 398
Modules in train mode: 460
Modules in eval mode: 0
Total FLOPs: 0
Epoch 19/19 ???????????????????????????????????????? 1738/1738 0:09:28 ? 0:00:00 3.16it/s v_num: 0.000`Trainer.fit` stopped: `max_epochs=20` reached.
Epoch 19/19 ???????????????????????????????????????? 1738/1738 0:09:28 ? 0:00:00 3.16it/s v_num: 0.000
Training time: 189.60706681013107 min
`weights_only` was not set, defaulting to `False`.

