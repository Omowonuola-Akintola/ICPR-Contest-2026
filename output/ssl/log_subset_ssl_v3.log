Seed set to 42
Using device: cpu
CPU cores available: 32
CPU cores using: 24
Data root directory: /home/krschap/rabina/data/s2a_subset
========================
Dataset config: DataConfig(data_root_dir='/home/krschap/rabina/data/s2a_subset', num_workers=24)
========================
Training config: TrainingConfig(experiment_out_dir='output/ssl_subset_v3_e50_b256_mem_8k_rm_norm', model='resnet50', in_channels=13, version=2, lr=0.0002, use_peft=False, temperature=0.15, memory_bank_size=4096, target_size=224, max_epochs=50, batch_size=128, ckpt_path=None, weight_decay=0.0001, moco_momentum=0.995)
32567
torch.Size([13, 224, 224])
Number of batches: 255
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/torchgeo/trainers/moco.py:209: UserWarning: MoCo v2 only uses 2 layers in its projection head
  warnings.warn('MoCo v2 only uses 2 layers in its projection head')
Full fine-tuning: backbone and projection head trainable...
+--------------------------+------------------------+------------------+--------------+
|          Module          |          Type          | Trainable Params | Total Params |
+--------------------------+------------------------+------------------+--------------+
|         backbone         |         ResNet         |    23,539,392    |  23,539,392  |
|    backbone_momentum     |         ResNet         |        0         |  23,539,392  |
|     projection_head      |   MoCoProjectionHead   |    26,222,848    |  26,222,848  |
| projection_head_momentum |   MoCoProjectionHead   |        0         |  26,222,848  |
|        criterion         |       NTXentLoss       |        0         |      0       |
|      augmentation1       | AugmentationSequential |        0         |      0       |
+--------------------------+------------------------+------------------+--------------+
Total trainable parameters: 49,762,240 (49.76 M)
Total parameters: 99,524,480 (99.52 M)
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.
USING DEVICE CONFIRMATION cuda:0
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
You are using a CUDA device ('NVIDIA GeForce RTX 4090 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ   â”ƒ Name                     â”ƒ Type                   â”ƒ Params â”ƒ Mode  â”ƒ FLOPs â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ backbone                 â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚
â”‚ 1 â”‚ backbone_momentum        â”‚ ResNet                 â”‚ 23.5 M â”‚ train â”‚     0 â”‚
â”‚ 2 â”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚
â”‚ 3 â”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 26.2 M â”‚ train â”‚     0 â”‚
â”‚ 4 â”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚
â”‚ 5 â”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 49.8 M
Non-trainable params: 49.8 M
Total params: 99.5 M
Total estimated model params size (MB): 398
Modules in train mode: 460
Modules in eval mode: 0
Total FLOPs: 0
/home/krschap/rabina/ICPR-Contest-2026/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
Epoch 49/49 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 255/255 0:01:35 â€¢ 0:00:00 2.81it/s v_num: 0.000`Trainer.fit` stopped: `max_epochs=50` reached.
Epoch 49/49 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 255/255 0:01:35 â€¢ 0:00:00 2.81it/s v_num: 0.000
Training time: 79.93534090121587 min
`weights_only` was not set, defaulting to `False`.